training:
  experiment_name: "ws8"
  total_timesteps: 100_000_000
  
  # Parallelism Config
  virtual_envs: 256
  real_envs: 64
  steps_per_virtual: 512
  
  # Optimization
  learning_rate: 3.0e-4
  batch_size: 8192
  n_epochs: 16
  gamma: 0.99
  
  # Checkpointing
  save_freq: 4
  verify_freq: 1
  n_verify_games: 5
  
  # Control
  start_stage: 1
  resume_checkpoint: null # Set path like "saves/ws9/update_30/STR.zip" (Folder path) to resume

curriculum:
  stage_1:
    description: "Static Ball - Learn to Strike"
    duration_updates: 30  # Run for 30 mega-updates
    env_config:
      ball_moving: false
      opponent_moving: false
      ball_spawn_dist_x: 0.02
      opponent_speed: 0.0
    rewards:
      ball_velocity_scale: 3.0
      goal_reward: 10.0
      spin_reward: 0.01      # High guidance
      alignment_reward: 0.1  # High guidance
      stagnation_penalty: 0.1
      use_distance_reward: false

  stage_2:
    description: "Moving Opponents - Learn to Aim"
    duration_updates: 30
    env_config:
      ball_moving: false
      opponent_moving: true
      ball_spawn_dist_x: 0.02
      opponent_speed: 0.1 # Slow random movement
    rewards:
      ball_velocity_scale: 4.0
      goal_reward: 15.0     # Increased incentive to finish
      spin_reward: 0.005    # Reduce guidance (wean off)
      alignment_reward: 0.05
      stagnation_penalty: 0.1
      use_distance_reward: false

  stage_3:
    description: "Dynamic Play - Intercept & Shoot"
    duration_updates: -1  # -1 means run until end of training
    env_config:
      ball_moving: true
      opponent_moving: true
      ball_spawn_dist_x: 0.15 # Further away
      opponent_speed: 0.3     # Faster opponents
    rewards:
      ball_velocity_scale: 5.0
      goal_reward: 20.0
      spin_reward: 0.0      # No hand-holding
      alignment_reward: 0.0 # Must learn to track naturally
      stagnation_penalty: 0.1
      use_distance_reward: false
